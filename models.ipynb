{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea93197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare model w/ best params from hyperparamsearch (randomsearch)\n",
    "def buildBest_2():\n",
    "    combo_input = keras.Input(shape=(X.shape[1], X.shape[2]), name='ecg_segment')\n",
    "\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1')(combo_input)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=3,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3')(i)\n",
    "\n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo\")\n",
    "    combo.summary()\n",
    "   \n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.001442874\n",
    "    \"\"\"\n",
    "    steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "    maximal_learning_rate=MAX_LR,\n",
    "    scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "    step_size=2 * steps_per_epoch\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        #optimizer= tf.keras.optimizers.SGD(clr),\n",
    "        metrics = ['accuracy'])\n",
    "  \n",
    "    return combo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708f17e-f0a0-4cd4-8d2a-f1874655070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBaseMask():\n",
    "    combo_input = keras.Input(shape=(X.shape[1], X.shape[2]), name='ecg_segment')\n",
    "    i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)\n",
    "\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv1')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=5,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3')(i)\n",
    "\n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo\")\n",
    "    combo.summary()\n",
    "   \n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.001\n",
    "    \"\"\"\n",
    "    steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "    maximal_learning_rate=MAX_LR,\n",
    "    scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "    step_size=2 * steps_per_epoch\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        #optimizer= tf.keras.optimizers.SGD(clr),\n",
    "        metrics = ['accuracy'])\n",
    "  \n",
    "    return combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae6c28-a269-4756-839d-de3bb834f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBase():\n",
    "    combo_input = keras.Input(shape=(X.shape[1], X.shape[2]), name='ecg_segment')\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv1')(combo_input)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=5,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3')(i)\n",
    "\n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo\")\n",
    "    combo.summary()\n",
    "   \n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.001\n",
    "    \"\"\"\n",
    "    steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "    maximal_learning_rate=MAX_LR,\n",
    "    scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "    step_size=2 * steps_per_epoch\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        #optimizer= tf.keras.optimizers.SGD(clr),\n",
    "        metrics = ['accuracy'])\n",
    "  \n",
    "    return combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd569f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#declare model w/ best params from hyperparamsearch (randomsearch)\n",
    "#include flexibity to allow for varying sized input \n",
    "#inspiration:\n",
    "#https://towardsdatascience.com/neural-network-for-input-of-variable-length-using-tensorflow-timedistributed-wrapper-a45972f4da51\n",
    "\n",
    "#inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "#x = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)(inputs)\n",
    "\n",
    "def build_mask():\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i = layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=3,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3')(i)\n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    \n",
    "    learning_rate = 0.001442874\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    \n",
    "    return combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mask():\n",
    "    \n",
    "    input_shape = (X.shape[1],X.shape[2],)\n",
    "\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Add the masking layer\n",
    "    masked_inputs = layers.Masking(mask_value=-2)(inputs)\n",
    "\n",
    "    # Add a LSTM layer\n",
    "    i = layers.LSTM(4, return_sequences=False)(masked_inputs)\n",
    "\n",
    "    # Flatten the output of the LSTM layer\n",
    "    i = layers.Flatten()(i)\n",
    "\n",
    "    # Add a Dense layer\n",
    "    dense_layer = layers.Dense(16, activation='relu')(i)\n",
    "\n",
    "    # Add the output layer\n",
    "    outputs = layers.Dense(2, activation='sigmoid')(dense_layer)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    #show model\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad78c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out simpler model w/ TimeDistributed wrapper. should accept variable length\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "\n",
    "def build_simple_TD():\n",
    "    \n",
    "    #input_shape = (X.shape[1],X.shape[2],)\n",
    "    input_shape = (None, 1,)\n",
    "\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Add a LSTM layer\n",
    "    #i = layers.TimeDistributed(layers.LSTM(4, return_sequences=False))(inputs)\n",
    "    i = layers.LSTM(4, return_sequences=False)(inputs)\n",
    "\n",
    "    \n",
    "    # Flatten the output of the LSTM layer\n",
    "    i = layers.TimeDistributed(layers.Flatten())(i)\n",
    "    #i = layers.Flatten()(i)\n",
    "\n",
    "    # Add a Dense layer\n",
    "    dense_layer = layers.TimeDistributed(layers.Dense(16, activation='relu'))(i)\n",
    "    #dense_layer = layers.Dense(16, activation='relu')(i)\n",
    "\n",
    "    # Add the output layer\n",
    "    outputs = layers.TimeDistributed(layers.Dense(2, activation='sigmoid'))(dense_layer)\n",
    "    #outputs = layers.Dense(2, activation='sigmoid')(dense_layer)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    #show model\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'],sample_weight_mode='temporal')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_more():\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i= layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    #i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = 2, name='Masking1')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1a')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1b')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=3,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2a')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=3,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2b')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3a')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3b')(i)\n",
    "    \n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.GRU(64, return_sequences=False, name='GRU')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.001442874\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_moreLSTM():\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i= layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    #i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = 2, name='Masking1')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1a')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1b')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=3,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2a')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=3,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2b')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3a')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3b')(i)\n",
    "    \n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.001442874\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine model to include best params. To use in LOGO analysis\n",
    "#model to use for fixed number of beats pr segment with -2 padding \n",
    "\n",
    "def build_mask_best():\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i = layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        #kernel_size=3,\n",
    "        kernel_size = 5,\n",
    "        activation = 'relu',name='conv2')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv3')(i)\n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    \n",
    "    learning_rate = 0.00072815\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    \n",
    "    return combo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine model to include best params. To use in LOGO analysis\n",
    "#model to use for fixed number of beats pr segment with -2 padding \n",
    "\n",
    "def build_bi_mask():\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i = layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        #kernel_size=3,\n",
    "        kernel_size = 5,\n",
    "        activation = 'relu',name='conv2')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv3')(i)\n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.Bidirectional(layers.LSTM(64, return_sequences=False, name='biLSTM'))(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"bi_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    \n",
    "    learning_rate = 0.00072815\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    \n",
    "    return combo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine model to include best params after keras_tuner and add dropout layers. To use in LOGO analysis\n",
    "\n",
    "def build_mask_best_drop():\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i = layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        #kernel_size=3,\n",
    "        kernel_size = 5,\n",
    "        activation = 'relu',name='conv2')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv3')(i)\n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "    i = layers.Dropout(0.2)(i)   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    \n",
    "    learning_rate = 0.00072815\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    \n",
    "    return combo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ceb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_moreLSTM_mask():\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i= layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1a')(combo_input)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1b')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=5,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2a')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=5,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2b')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv3a')(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv3b')(i)\n",
    "    \n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.Dropout(0.2)(i)\n",
    "    i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_2')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.00072815\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e129f765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T10:45:45.659696Z",
     "iopub.status.busy": "2023-04-21T10:45:45.659028Z",
     "iopub.status.idle": "2023-04-21T10:45:45.679100Z",
     "shell.execute_reply": "2023-04-21T10:45:45.678326Z",
     "shell.execute_reply.started": "2023-04-21T10:45:45.659642Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_explore(top, denseLayers, typeLSTM='1 LSTM', dropout=False):\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i = layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)\n",
    "      \n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1a')(i)\n",
    "    if (top==2):\n",
    "        i = layers.Conv1D(\n",
    "            filters = 32,\n",
    "            #tuning kernel size layer 1\n",
    "            kernel_size=3,\n",
    "            activation = 'relu',name='conv1b')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    if (dropout==True):\n",
    "        i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=5,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2a')(i)\n",
    "    if (top==2):\n",
    "        i = layers.Conv1D(\n",
    "            filters = 64 , \n",
    "            #tuning kernel size layer 2\n",
    "            kernel_size=5,\n",
    "            #kernel_size = 5,\n",
    "            activation = 'relu',name='conv2b')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    if (dropout==True):\n",
    "        i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv3a')(i)\n",
    "    if (top==2):\n",
    "        i = layers.Conv1D(\n",
    "            filters = 32 ,\n",
    "            #tuning kernel size layer 3\n",
    "            kernel_size=3,\n",
    "            activation = 'relu',name='conv3b')(i)\n",
    "    \n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    if (dropout==True):\n",
    "        i = layers.Dropout(0.2)(i)\n",
    "    \n",
    "    if (typeLSTM=='1 LSTM'):\n",
    "        i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    if (typeLSTM=='2 LSTM'):\n",
    "        i = layers.LSTM(32, return_sequences=True, name='LSTM1')(i) \n",
    "        i = layers.LSTM(64, return_sequences=False, name='LSTM2')(i) \n",
    "    if (typeLSTM=='1 biLSTM'):\n",
    "        i = layers.Bidirectional(layers.LSTM(64, return_sequences=False, name='biLSTM'))(i) \n",
    "\n",
    "\n",
    "    #i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    #i = layers.GlobalMaxPooling1D(name='global_max_pooling1d')(i) # Add GlobalMaxPooling1D layer here\n",
    "\n",
    "    for j in np.arange(0,denseLayers):\n",
    "        i = layers.Dense(128/(2 ** j),  name='dense_'+str(j+1))(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_end')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.00072815\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    return combo\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d423e5b",
   "metadata": {},
   "source": [
    "### add deeper model to best performing new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep():\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i = layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)   \n",
    "    \n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1a')(combo_input) \n",
    "    i = layers.Conv1D(\n",
    "            filters = 32,\n",
    "            #tuning kernel size layer 1\n",
    "            kernel_size=3,\n",
    "            activation = 'relu',name='conv1b')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    i = layers.Dropout(0.2,name='dropout1')(i)\n",
    "    \n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=5,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2a')(i)\n",
    "    \n",
    "    i = layers.Conv1D(\n",
    "            filters = 64 , \n",
    "            #tuning kernel size layer 2\n",
    "            kernel_size=5,\n",
    "            #kernel_size = 5,\n",
    "            activation = 'relu',name='conv2b')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    i = layers.Dropout(0.2, name='dropout2')(i)\n",
    "    \n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv3a')(i)\n",
    "    i = layers.Conv1D(\n",
    "            filters = 32 ,\n",
    "            #tuning kernel size layer 3\n",
    "            kernel_size=3,\n",
    "            activation = 'relu',name='conv3b')(i)\n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    i = layers.Dropout(0.2, name='dropout3')(i)   \n",
    "    \n",
    "    i = layers.Conv1D(\n",
    "            filters = 32 , \n",
    "            #tuning kernel size layer 4\n",
    "            kernel_size=5,\n",
    "            #kernel_size = 5,\n",
    "            activation = 'relu',name='conv4b')(i)\n",
    "    i = layers.BatchNormalization(name='batch4')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool4')(i)\n",
    "    i = layers.Dropout(0.2 ,name='dropout4')(i)    \n",
    "    \n",
    "    i = layers.Bidirectional(layers.LSTM(64, return_sequences=False, name='biLSTM'))(i) \n",
    "    i = layers.Dense(128,  name='dense_1')(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_end')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.00072815\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    return combo\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe701b",
   "metadata": {},
   "source": [
    "## add explorative model designed for fixed length input\n",
    "- using parameter from tuning of that base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff11f6c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T10:45:45.659696Z",
     "iopub.status.busy": "2023-04-21T10:45:45.659028Z",
     "iopub.status.idle": "2023-04-21T10:45:45.679100Z",
     "shell.execute_reply": "2023-04-21T10:45:45.678326Z",
     "shell.execute_reply.started": "2023-04-21T10:45:45.659642Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_explore_fixed(top, denseLayers, typeLSTM='1 LSTM', dropout=False):\n",
    "    combo_input = keras.Input(shape=(X.shape[1],X.shape[2]), name='ecg_segment')\n",
    "    #combo_input = keras.Input(shape=(None,), name='ecg_segment') \n",
    "    #i = layers.Embedding(input_dim=X.shape[1], output_dim=1 ,mask_zero=True, name='Embedded1')(combo_input)\n",
    "    #i = layers.Masking(input_shape=(X.shape[1],X.shape[2]), mask_value = -2, name='Masking1')(combo_input)\n",
    "      \n",
    "    i = layers.Conv1D(\n",
    "        filters = 32,\n",
    "        #tuning kernel size layer 1\n",
    "        kernel_size=3,\n",
    "        activation = 'relu',name='conv1a')(combo_input)\n",
    "    if (top==2):\n",
    "        i = layers.Conv1D(\n",
    "            filters = 32,\n",
    "            #tuning kernel size layer 1\n",
    "            kernel_size=3,\n",
    "            activation = 'relu',name='conv1b')(i)\n",
    "    i = layers.BatchNormalization(name='batch1')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool1')(i)\n",
    "    if (dropout==True):\n",
    "        i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 64 , \n",
    "        #tuning kernel size layer 2\n",
    "        kernel_size=3,\n",
    "        #kernel_size = 5,\n",
    "        activation = 'relu',name='conv2a')(i)\n",
    "    if (top==2):\n",
    "        i = layers.Conv1D(\n",
    "            filters = 64 , \n",
    "            #tuning kernel size layer 2\n",
    "            kernel_size=3,\n",
    "            #kernel_size = 5,\n",
    "            activation = 'relu',name='conv2b')(i)\n",
    "    i = layers.BatchNormalization(name='batch2')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool2')(i)\n",
    "    if (dropout==True):\n",
    "        i = layers.Dropout(0.2)(i)\n",
    "    i = layers.Conv1D(\n",
    "        filters = 32 ,\n",
    "        #tuning kernel size layer 3\n",
    "        kernel_size=5,\n",
    "        activation = 'relu',name='conv3a')(i)\n",
    "    if (top==2):\n",
    "        i = layers.Conv1D(\n",
    "            filters = 32 ,\n",
    "            #tuning kernel size layer 3\n",
    "            kernel_size=5,\n",
    "            activation = 'relu',name='conv3b')(i)\n",
    "    \n",
    "    i = layers.BatchNormalization(name='batch3')(i)\n",
    "    i = layers.MaxPooling1D(pool_size=2, strides=2, padding='same',name='max_pool3')(i)\n",
    "    if (dropout==True):\n",
    "        i = layers.Dropout(0.2)(i)\n",
    "    \n",
    "    if (typeLSTM=='1 LSTM'):\n",
    "        i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    if (typeLSTM=='2 LSTM'):\n",
    "        i = layers.LSTM(32, return_sequences=True, name='LSTM1')(i) \n",
    "        i = layers.LSTM(64, return_sequences=False, name='LSTM2')(i) \n",
    "    if (typeLSTM=='1 biLSTM'):\n",
    "        i = layers.Bidirectional(layers.LSTM(64, return_sequences=False, name='biLSTM'))(i) \n",
    "\n",
    "\n",
    "    #i = layers.LSTM(64, return_sequences=False, name='LSTM')(i) \n",
    "    #i = layers.GlobalMaxPooling1D(name='global_max_pooling1d')(i) # Add GlobalMaxPooling1D layer here\n",
    "\n",
    "    for j in np.arange(0,denseLayers):\n",
    "        i = layers.Dense(128/(2 ** j),  name='dense_'+str(j+1))(i)\n",
    "   \n",
    "    combo_output = layers.Dense(2, activation='sigmoid', name='dense_end')(i)\n",
    "\n",
    "    combo = keras.Model(combo_input, combo_output, name=\"combo_mask\")\n",
    "    combo.summary()\n",
    "    #tuning learning_rate\n",
    "    learning_rate = 0.001442874\n",
    "    combo.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    return combo\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "806d57ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T08:34:10.716444Z",
     "iopub.status.busy": "2023-04-21T08:34:10.715670Z",
     "iopub.status.idle": "2023-04-21T08:34:10.731392Z",
     "shell.execute_reply": "2023-04-21T08:34:10.730311Z",
     "shell.execute_reply.started": "2023-04-21T08:34:10.716389Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "number=1\n",
    "\n",
    "for j in np.arange(1,number+1):\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee974fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "N=5\n",
    "foo=np.random.random((N,N))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
